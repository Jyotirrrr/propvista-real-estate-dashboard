{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "al_EQ5-Nowan"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# FINAL REAL ESTATE PREDICTION + ENRICHMENT PROJECT (A‚ÄìZ)\n",
        "# -----------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import shap\n",
        "import plotly.express as px\n",
        "import gradio as gr\n",
        "import xgboost as xgb\n",
        "from geopy.distance import geodesic\n",
        "from google.colab import files\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 1: FILE UPLOAD + DATA LOADING\n",
        "# -----------------------------\n",
        "print(\"\\nüì§ Please upload property.csv, uber.csv, restaurant.csv, crime.csv, and entertainment.csv\")\n",
        "uploaded = files.upload()\n",
        "external_data = {}\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    try:\n",
        "        if filename.lower().endswith('.xlsx'):\n",
        "            content = pd.read_excel(io.BytesIO(uploaded[filename]))\n",
        "        else:\n",
        "            content = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "    except UnicodeDecodeError:\n",
        "        content = pd.read_csv(io.BytesIO(uploaded[filename]), encoding='latin1')\n",
        "    except pd.errors.ParserError:\n",
        "        print(f\"‚ùå Parser error in {filename}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    if 'uber' in filename.lower():\n",
        "        df_uber = content\n",
        "    elif 'crime' in filename.lower():\n",
        "        external_data['crime'] = content\n",
        "    elif 'entertain' in filename.lower():\n",
        "        external_data['entertainment'] = content\n",
        "    elif 'restaurant' in filename.lower():\n",
        "        external_data['restaurant'] = content\n",
        "    elif 'property' in filename.lower() or 'house' in filename.lower():\n",
        "        df = content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "0X60M3f_pBeo",
        "outputId": "3a18f2a3-8792-4cbc-f03f-73a827ba374e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì§ Please upload property.csv, uber.csv, restaurant.csv, crime.csv, and entertainment.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2aab91fc-8c85-444e-a7ae-c77966b605f1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2aab91fc-8c85-444e-a7ae-c77966b605f1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Bengaluru_Restaurants.csv to Bengaluru_Restaurants.csv\n",
            "Saving South Crime Details.xlsx to South Crime Details.xlsx\n",
            "Saving indian-movie-theatres.txt to indian-movie-theatres.txt\n",
            "Saving uber.csv to uber.csv\n",
            "Saving Bengaluru_House_Data.csv to Bengaluru_House_Data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/openpyxl/worksheet/_reader.py:223: UserWarning: Cell D5859 is marked as a date but the serial value 6616895 is outside the limits for dates. The cell will be treated as an error.\n",
            "  warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# STEP 2: CLEAN PROPERTY DATA\n",
        "# -----------------------------\n",
        "df.dropna(subset=['location', 'size', 'total_sqft', 'price'], inplace=True)\n",
        "df['location'] = df['location'].astype(str).str.strip()\n",
        "df['bhk'] = df['size'].str.extract(r'(\\d+)').astype(float)\n",
        "df['total_sqft_clean'] = df['total_sqft'].apply(lambda x: np.mean([float(i) for i in str(x).split('-')]) if '-' in str(x) else pd.to_numeric(x, errors='coerce'))\n",
        "df.dropna(subset=['total_sqft_clean'], inplace=True)\n",
        "df['price_per_sqft'] = (df['price'] * 1e5) / df['total_sqft_clean']\n",
        "df['bath'] = df['bath'].fillna(df['bath'].median())\n",
        "df['balcony'] = df['balcony'].fillna(0)"
      ],
      "metadata": {
        "id": "boujj806pkEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 3: MERGE EXTERNAL FEATURES\n",
        "# -----------------------------\n",
        "df_features = df.copy()\n",
        "df_features['location'] = df_features['location'].astype(str).str.strip()\n",
        "\n",
        "if 'crime' in external_data and 'location' in external_data['crime'].columns:\n",
        "    external_data['crime']['location'] = external_data['crime']['location'].astype(str).str.strip()\n",
        "    df_features = df_features.merge(external_data['crime'], on='location', how='left')\n",
        "else:\n",
        "    df_features['crime_rate'] = np.random.uniform(2, 10, len(df_features))\n",
        "\n",
        "if 'entertainment' in external_data and 'location' in external_data['entertainment'].columns:\n",
        "    external_data['entertainment']['location'] = external_data['entertainment']['location'].astype(str).str.strip()\n",
        "    df_features = df_features.merge(external_data['entertainment'], on='location', how='left')\n",
        "else:\n",
        "    df_features['entertainment_centers'] = np.random.randint(1, 10, len(df_features))\n",
        "\n",
        "if 'restaurant' in external_data and 'location' in external_data['restaurant'].columns:\n",
        "    external_data['restaurant']['location'] = external_data['restaurant']['location'].astype(str).str.strip()\n",
        "    rest_density = external_data['restaurant'].groupby('location').size().reset_index(name='restaurant_count')\n",
        "    df_features = df_features.merge(rest_density, on='location', how='left')\n",
        "else:\n",
        "    df_features['restaurant_count'] = np.random.randint(5, 50, len(df_features))\n",
        "\n",
        "crime_max = df_features['crime_rate'].max()\n",
        "df_features['crime_score'] = (crime_max - df_features['crime_rate']) / crime_max * 10\n",
        "df_features['entertainment_score'] = df_features['entertainment_centers'] / df_features['entertainment_centers'].max() * 10\n",
        "rest_max = df_features['restaurant_count'].max()\n",
        "df_features['restaurant_score'] = df_features['restaurant_count'] / rest_max * 10\n"
      ],
      "metadata": {
        "id": "EkDgec9_prR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 4: GEO-PROXIMITY SCORE\n",
        "# -----------------------------\n",
        "ref_point = (12.9716, 77.5946)\n",
        "def dummy_coordinates(location):\n",
        "    return (12.9 + hash(location)%10/100, 77.5 + hash(location)%10/100)\n",
        "\n",
        "df_features['distance_to_center'] = df_features['location'].apply(lambda loc: geodesic(ref_point, dummy_coordinates(loc)).km)\n",
        "dist_max = df_features['distance_to_center'].max()\n",
        "df_features['proximity_score'] = (dist_max - df_features['distance_to_center']) / dist_max * 10"
      ],
      "metadata": {
        "id": "LlW_tmm5qKaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 5: ADVANCED FEATURES\n",
        "# -----------------------------\n",
        "df_features['room_density'] = df_features['total_sqft_clean'] / (df_features['bhk'] + df_features['bath'])\n",
        "df_features['popularity_score'] = df_features.groupby('location')['price'].transform('count')\n",
        "df_features['popularity_score'] = df_features['popularity_score'] / df_features['popularity_score'].max() * 10\n",
        "df_features['volatility_score'] = df_features.groupby('location')['price'].transform('std')\n",
        "df_features['volatility_score'] = df_features['volatility_score'].fillna(0)"
      ],
      "metadata": {
        "id": "BZ_JxRccqw2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 6: MODEL TRAINING\n",
        "# -----------------------------\n",
        "features = ['total_sqft_clean', 'bhk', 'bath', 'balcony', 'price_per_sqft',\n",
        "            'crime_score', 'entertainment_score', 'proximity_score', 'restaurant_score',\n",
        "            'room_density', 'popularity_score', 'volatility_score']\n",
        "X = df_features[features]\n",
        "y = df_features['price'] * 1e5\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "base_models = [\n",
        "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
        "    ('xgb', xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=0))\n",
        "]\n",
        "stack_model = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "preds = stack_model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, preds)\n",
        "r2 = r2_score(y_test, preds)\n",
        "\n",
        "print(f\"\\nüìä Model Performance:\")\n",
        "print(f\"MAE: ‚Çπ{mae:,.0f}\")\n",
        "print(f\"R¬≤ Score: {r2:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNoyksc4q0Gu",
        "outputId": "9b467e6a-808e-45f7-eda3-378440502bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Model Performance:\n",
            "MAE: ‚Çπ506,501\n",
            "R¬≤ Score: 0.960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 7: SHAP EXPLAINABILITY\n",
        "# -----------------------------\n",
        "explainer = shap.Explainer(stack_model.predict, X_train)\n",
        "shap_values = explainer(X_test[:100])\n",
        "shap.summary_plot(shap_values, X_test[:100], show=False)\n",
        "plt.title(\"SHAP Summary Plot\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"shap_summary_plot.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxnvBssBriLv",
        "outputId": "8b40c1ba-5ef1-45c5-fe8c-938bd867d920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PermutationExplainer explainer: 101it [02:23,  1.45s/it]\n",
            "/tmp/ipython-input-12-2907696779.py:6: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  shap.summary_plot(shap_values, X_test[:100], show=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 8: TIME SERIES (PHASE 6)\n",
        "# -----------------------------\n",
        "if 'Date' in df.columns:\n",
        "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "    df['year'] = df['Date'].dt.year\n",
        "    yearly = df.groupby('year')['price'].mean().reset_index()\n",
        "    fig = px.line(yearly, x='year', y='price', title='Average Price Trend Over Years')\n",
        "    fig.write_html(\"price_trend.html\")"
      ],
      "metadata": {
        "id": "S9YsZwkMsdid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 9: EXPORT ENRICHED DATA\n",
        "# -----------------------------\n",
        "df_features.to_csv(\"real_estate_enriched_v2.csv\", index=False)\n",
        "files.download(\"real_estate_enriched_v2.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_HmkJMwGsMOw",
        "outputId": "7064da76-e6aa-4a59-8f0c-5be0f2a2ce3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9cbb718e-a476-4055-95f5-0b19b7c40a63\", \"real_estate_enriched_v2.csv\", 3437565)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# STEP 10: GRADIO DASHBOARD\n",
        "# -----------------------------\n",
        "def predict_all(location, sqft, bhk, bath, balcony):\n",
        "    try:\n",
        "        df_loc = df_features[df_features['location'] == location]\n",
        "        if df_loc.empty:\n",
        "            avg_pps = df_features['price_per_sqft'].mean()\n",
        "            avg_crime = df_features['crime_score'].mean()\n",
        "            avg_ent = df_features['entertainment_score'].mean()\n",
        "            avg_prox = df_features['proximity_score'].mean()\n",
        "            avg_rest = df_features['restaurant_score'].mean()\n",
        "            avg_density = df_features['room_density'].mean()\n",
        "            avg_pop = df_features['popularity_score'].mean()\n",
        "            avg_vol = df_features['volatility_score'].mean()\n",
        "            location_avg_price = df_features['price'].mean() * 1e5\n",
        "        else:\n",
        "            avg_pps = df_loc['price_per_sqft'].mean()\n",
        "            avg_crime = df_loc['crime_score'].mean()\n",
        "            avg_ent = df_loc['entertainment_score'].mean()\n",
        "            avg_prox = df_loc['proximity_score'].mean()\n",
        "            avg_rest = df_loc['restaurant_score'].mean()\n",
        "            avg_density = df_loc['room_density'].mean()\n",
        "            avg_pop = df_loc['popularity_score'].mean()\n",
        "            avg_vol = df_loc['volatility_score'].mean()\n",
        "            location_avg_price = df_loc['price'].mean() * 1e5\n",
        "\n",
        "        input_df = pd.DataFrame([[sqft, bhk, bath, balcony, avg_pps, avg_crime, avg_ent, avg_prox, avg_rest,\n",
        "                                  sqft / (bhk + bath), avg_pop, avg_vol]], columns=features)\n",
        "        predicted_price = stack_model.predict(input_df)[0]\n",
        "        status = \"‚úÖ Fairly Priced\" if abs(predicted_price - location_avg_price) < 0.2 * location_avg_price else \"‚ö†Ô∏è Overpriced\"\n",
        "\n",
        "        fig = px.bar(\n",
        "            x=['Crime', 'Entertainment', 'Proximity', 'Restaurant', 'Room Density', 'Popularity', 'Volatility'],\n",
        "            y=[avg_crime, avg_ent, avg_prox, avg_rest, avg_density, avg_pop, avg_vol],\n",
        "            labels={'x': 'Factor', 'y': 'Score'},\n",
        "            title=f\"Area Score Breakdown: {location}\"\n",
        "        )\n",
        "\n",
        "        return (\n",
        "            f\"‚Çπ{int(predicted_price):,}\",\n",
        "            round(avg_crime, 2),\n",
        "            round(avg_ent, 2),\n",
        "            round(avg_prox, 2),\n",
        "            round(avg_rest, 2),\n",
        "            round(avg_density, 2),\n",
        "            round(avg_pop, 2),\n",
        "            round(avg_vol, 2),\n",
        "            status,\n",
        "            fig\n",
        "        )\n",
        "    except Exception as e:\n",
        "        return (\"Error\", \"Error\", \"Error\", \"Error\", \"Error\", \"Error\", \"Error\", \"Error\", str(e), None)\n",
        "\n",
        "unique_locations = sorted(df_features['location'].unique())\n",
        "demo = gr.Interface(\n",
        "    fn=predict_all,\n",
        "    inputs=[\n",
        "        gr.Dropdown(choices=unique_locations, label=\"Location / Area\"),\n",
        "        gr.Number(label=\"Total Square Feet\"),\n",
        "        gr.Number(label=\"BHK\"),\n",
        "        gr.Number(label=\"Bathrooms\"),\n",
        "        gr.Number(label=\"Balconies\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Estimated Price (‚Çπ)\"),\n",
        "        gr.Textbox(label=\"Crime Score\"),\n",
        "        gr.Textbox(label=\"Entertainment Score\"),\n",
        "        gr.Textbox(label=\"Proximity Score\"),\n",
        "        gr.Textbox(label=\"Restaurant Score\"),\n",
        "        gr.Textbox(label=\"Room Density\"),\n",
        "        gr.Textbox(label=\"Popularity Score\"),\n",
        "        gr.Textbox(label=\"Volatility Score\"),\n",
        "        gr.Textbox(label=\"Pricing Status\"),\n",
        "        gr.Plot(label=\"Score Breakdown\")\n",
        "    ],\n",
        "    title=\"üè° PropVista: 360¬∞ Real Estate Analytics\",\n",
        "    description=\"Enter your location and property specs to get price, safety, and livability insights.\"\n",
        ")\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "3oK7_OAIslsg",
        "outputId": "c96d79a5-b3a4-4bca-bd5d-bf915bbf0506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e682f52ae52ad71cf5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e682f52ae52ad71cf5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}